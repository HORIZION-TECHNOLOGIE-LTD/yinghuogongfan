{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen AgentChat Quickstart\n",
    "\n",
    "This notebook provides a quick introduction to AutoGen's AgentChat, adapted for SurfSense integration.\n",
    "\n",
    "Based on the official [AutoGen AgentChat Quickstart](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/quickstart.html)\n",
    "\n",
    "## What is AgentChat?\n",
    "\n",
    "AgentChat is a high-level API in AutoGen for building multi-agent applications. It provides:\n",
    "- Pre-built agent types for common scenarios\n",
    "- Built-in group chat coordination\n",
    "- Easy integration with LLMs\n",
    "- Code execution capabilities\n",
    "- Human-in-the-loop support\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "First, set up your LLM configuration. AutoGen supports multiple LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Configure the LLM\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Two-Agent Conversation\n",
    "\n",
    "The simplest AutoGen setup: an assistant agent and a user proxy agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant agent\n",
    "assistant = AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful AI assistant.\"\n",
    ")\n",
    "\n",
    "# Create a user proxy agent\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",  # No human input needed for this example\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\"work_dir\": \"coding\"},\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"Tell me a joke about programming.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Code Execution\n",
    "\n",
    "AutoGen agents can write and execute code automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a coding assistant\n",
    "coder = AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are an expert Python programmer.\n",
    "    Write Python code to solve problems.\n",
    "    Wrap the code in a code block that specifies the script type.\"\"\"\n",
    ")\n",
    "\n",
    "# User proxy with code execution enabled\n",
    "executor = UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,  # Set to True if you have Docker\n",
    "    },\n",
    ")\n",
    "\n",
    "# Start coding task\n",
    "executor.initiate_chat(\n",
    "    coder,\n",
    "    message=\"\"\"Create a Python script that:\n",
    "    1. Generates a list of 10 random numbers between 1 and 100\n",
    "    2. Calculates their mean and standard deviation\n",
    "    3. Creates a simple bar chart visualization\n",
    "    Save the chart as 'random_numbers.png'\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Group Chat with Multiple Agents\n",
    "\n",
    "Create a group chat with specialized agents working together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized agents\n",
    "planner = AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a planning expert.\n",
    "    Your job is to break down complex tasks into step-by-step plans.\n",
    "    Be specific and detailed in your planning.\"\"\"\n",
    ")\n",
    "\n",
    "engineer = AssistantAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a software engineer.\n",
    "    Follow the plan provided by the Planner and write clean, efficient code.\n",
    "    Include comments and error handling.\"\"\"\n",
    ")\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a code reviewer.\n",
    "    Review code for:\n",
    "    - Correctness\n",
    "    - Best practices\n",
    "    - Potential bugs\n",
    "    - Performance issues\n",
    "    Provide constructive feedback.\"\"\"\n",
    ")\n",
    "\n",
    "executor = UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"work_dir\": \"coding\"},\n",
    ")\n",
    "\n",
    "# Create group chat\n",
    "groupchat = GroupChat(\n",
    "    agents=[executor, planner, engineer, critic],\n",
    "    messages=[],\n",
    "    max_round=12,\n",
    ")\n",
    "\n",
    "manager = GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Start the group chat\n",
    "executor.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"Create a Python function that:\n",
    "    1. Takes a text file path as input\n",
    "    2. Counts the frequency of each word\n",
    "    3. Returns the top 10 most common words\n",
    "    \n",
    "    Please plan, implement, and review the solution.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Human-in-the-Loop\n",
    "\n",
    "Enable human feedback during agent conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# User proxy that asks for human input\n",
    "user_proxy_human = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"ALWAYS\",  # Always ask for human input\n",
    "    max_consecutive_auto_reply=5,\n",
    ")\n",
    "\n",
    "# Start conversation (will wait for your input)\n",
    "user_proxy_human.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"Help me plan a data analysis project.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Function Calling\n",
    "\n",
    "Equip agents with custom functions they can call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "def search_documents(query: str, max_results: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search documents in the knowledge base.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        max_results: Maximum number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        Search results as a formatted string\n",
    "    \"\"\"\n",
    "    # This would integrate with SurfSense's search functionality\n",
    "    return f\"\"\"Found {max_results} documents matching '{query}':\n",
    "    1. Document about AI agents and frameworks\n",
    "    2. Tutorial on RAG systems\n",
    "    3. Guide to vector embeddings\n",
    "    4. Best practices for LLM applications\n",
    "    5. Introduction to multi-agent systems\"\"\"\n",
    "\n",
    "def get_document_content(doc_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the content of a specific document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document ID\n",
    "    \n",
    "    Returns:\n",
    "        Document content\n",
    "    \"\"\"\n",
    "    return f\"Content of document {doc_id}: This is a sample document about AI agents...\"\n",
    "\n",
    "# Create assistant with function calling\n",
    "assistant_with_functions = AssistantAgent(\n",
    "    name=\"ResearchAssistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a research assistant with access to a document database.\n",
    "    Use the available functions to search and retrieve information.\"\"\"\n",
    ")\n",
    "\n",
    "# Register functions\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    function_map={\n",
    "        \"search_documents\": search_documents,\n",
    "        \"get_document_content\": get_document_content,\n",
    "    },\n",
    ")\n",
    "\n",
    "# The assistant can now call these functions\n",
    "user_proxy.initiate_chat(\n",
    "    assistant_with_functions,\n",
    "    message=\"Search for documents about RAG systems and summarize the key concepts.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: SurfSense Integration Pattern\n",
    "\n",
    "How to integrate AutoGen with SurfSense's backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code for SurfSense integration\n",
    "\n",
    "class SurfSenseAgentSystem:\n",
    "    \"\"\"Integration of AutoGen with SurfSense.\"\"\"\n",
    "    \n",
    "    def __init__(self, user_id: int, search_space_id: int):\n",
    "        self.user_id = user_id\n",
    "        self.search_space_id = search_space_id\n",
    "        self.setup_agents()\n",
    "    \n",
    "    def setup_agents(self):\n",
    "        \"\"\"Initialize agents with SurfSense-specific functions.\"\"\"\n",
    "        \n",
    "        # Create research agent with document search\n",
    "        self.researcher = AssistantAgent(\n",
    "            name=\"Researcher\",\n",
    "            llm_config=llm_config,\n",
    "            system_message=\"\"\"You are a research assistant.\n",
    "            Use document search to find relevant information.\n",
    "            Always cite your sources.\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Create analyst agent\n",
    "        self.analyst = AssistantAgent(\n",
    "            name=\"Analyst\",\n",
    "            llm_config=llm_config,\n",
    "            system_message=\"\"\"You are a data analyst.\n",
    "            Analyze information and provide insights.\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Create user proxy with SurfSense functions\n",
    "        self.user_proxy = UserProxyAgent(\n",
    "            name=\"User\",\n",
    "            human_input_mode=\"NEVER\",\n",
    "            function_map={\n",
    "                \"search_documents\": self.search_surfsense_documents,\n",
    "                \"get_document\": self.get_surfsense_document,\n",
    "                \"create_podcast\": self.create_surfsense_podcast,\n",
    "            },\n",
    "        )\n",
    "    \n",
    "    def search_surfsense_documents(self, query: str) -> str:\n",
    "        \"\"\"Search documents in user's SurfSense search space.\"\"\"\n",
    "        # Call SurfSense's hybrid search\n",
    "        # return results\n",
    "        pass\n",
    "    \n",
    "    def get_surfsense_document(self, doc_id: int) -> str:\n",
    "        \"\"\"Get full document content from SurfSense.\"\"\"\n",
    "        # Fetch document from database\n",
    "        # return content\n",
    "        pass\n",
    "    \n",
    "    def create_surfsense_podcast(self, content: str, title: str) -> str:\n",
    "        \"\"\"Create a podcast from the conversation.\"\"\"\n",
    "        # Call SurfSense podcast generation\n",
    "        # return podcast_url\n",
    "        pass\n",
    "    \n",
    "    def research_and_analyze(self, query: str) -> dict:\n",
    "        \"\"\"Run a research and analysis task.\"\"\"\n",
    "        groupchat = GroupChat(\n",
    "            agents=[self.user_proxy, self.researcher, self.analyst],\n",
    "            messages=[],\n",
    "            max_round=10,\n",
    "        )\n",
    "        \n",
    "        manager = GroupChatManager(\n",
    "            groupchat=groupchat,\n",
    "            llm_config=llm_config,\n",
    "        )\n",
    "        \n",
    "        self.user_proxy.initiate_chat(\n",
    "            manager,\n",
    "            message=query,\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"conversation\": groupchat.messages,\n",
    "            \"summary\": \"Analysis complete\",\n",
    "        }\n",
    "\n",
    "# Usage example\n",
    "# agent_system = SurfSenseAgentSystem(user_id=123, search_space_id=1)\n",
    "# result = agent_system.research_and_analyze(\"Analyze my research papers on AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Termination Conditions\n",
    "\n",
    "Control when conversations should end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom termination condition\n",
    "def my_termination_condition(message: dict) -> bool:\n",
    "    \"\"\"Terminate if the word 'TERMINATE' is in the message.\"\"\"\n",
    "    content = message.get(\"content\", \"\")\n",
    "    return \"TERMINATE\" in content\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful assistant.\n",
    "    When the task is complete, end your message with 'TERMINATE'.\"\"\"\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=my_termination_condition,\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"Count from 1 to 5.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Clear System Messages**: Give agents specific roles and instructions\n",
    "2. **Termination Conditions**: Always set clear termination conditions\n",
    "3. **Error Handling**: Implement proper error handling for code execution\n",
    "4. **Token Management**: Monitor token usage to control costs\n",
    "5. **Security**: Use Docker for code execution in production\n",
    "6. **Testing**: Test agent behaviors thoroughly before deployment\n",
    "7. **Logging**: Keep track of conversations for debugging and improvement\n",
    "\n",
    "## Advanced Topics\n",
    "\n",
    "- **Nested Chats**: Create hierarchical agent structures\n",
    "- **State Management**: Maintain context across multiple conversations\n",
    "- **Custom Agents**: Extend base agent classes for specialized behavior\n",
    "- **Async Operations**: Use async agents for better performance\n",
    "- **RAG Integration**: Combine with retrieval-augmented generation\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [AutoGen Official Documentation](https://microsoft.github.io/autogen/stable/)\n",
    "- [AutoGen AgentChat Guide](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/)\n",
    "- [AutoGen Examples](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/)\n",
    "- [SurfSense Documentation](https://www.surfsense.net/docs/)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Try the examples above with your own use cases\n",
    "2. Explore the group chat notebook for advanced multi-agent patterns\n",
    "3. Integrate with SurfSense's document retrieval and podcast generation\n",
    "4. Build your own specialized agents for your workflow\n",
    "5. Experiment with different LLM models and configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
